{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat by using ollama api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import HTML, display, Markdown\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a system message list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Describe a full cycle of the Recruitment process\"},\n",
    "]\n",
    "\n",
    "# create a request payload\n",
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python Ollama package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the web page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage Content\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama Python library 0.4 with function calling improvements Â· Ollama Blog\n"
     ]
    }
   ],
   "source": [
    "webcontent = Website(\"https://ollama.com/blog/functions-as-tools\")\n",
    "print(webcontent.title)\n",
    "# print(webcontent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}. \\\n",
    "    The contents of this website is as follows; \\\n",
    "    Please provide a short summary of this website in markdown. \\\n",
    "    If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    \n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Summary of Ollama Python Library 0.4 Release\n",
      "### Function Calling Improvements and Updates\n",
      "\n",
      "The latest release of the Ollama Python library, version 0.4, brings several improvements and updates to its function calling capabilities.\n",
      "\n",
      "#### New Functionality\n",
      "\n",
      "*   Functions can now be provided as tools, allowing for more flexibility in how users interact with the library.\n",
      "*   Full typing support has been added throughout the library, enabling direct object access while maintaining existing functionality.\n",
      "*   Examples have been updated on the Ollama Python GitHub repository to showcase the new features.\n",
      "\n",
      "#### Key Benefits\n",
      "\n",
      "*   Improved usability and flexibility through function calling\n",
      "*   Enhanced typing support for more robust data handling\n",
      "*   Updated examples demonstrate the capabilities of the library\n",
      "\n",
      "#### News/Announcements\n",
      "\n",
      "*   The release marks an exciting milestone in the development of the Ollama Python library, with several notable improvements and additions.\n",
      "\n",
      "### Getting Started\n",
      "\n",
      "To start using the Ollama Python library, users can install or upgrade it using `pip install -U ollama`.\n",
      "\n",
      "### Example Usage\n",
      "\n",
      "```python\n",
      "import ollama\n",
      "\n",
      "def add_two_numbers(a: int, b: int) -> int:\n",
      "    \"\"\"Add two numbers\"\"\"\n",
      "    return a + b\n",
      "\n",
      "response = ollama.chat(\n",
      "    'llama3.1',\n",
      "    messages=[{'role': 'user', 'content': 'What is 10 + 10?'}],\n",
      "    tools=[add_two_numbers]\n",
      ")\n",
      "\n",
      "for tool in response.message.tool_calls or []:\n",
      "    function_to_call = available_functions.get(tool.function.name)\n",
      "    if function_to_call:\n",
      "        print('Function output:', function_to_call(**tool.function.arguments))\n",
      "    else:\n",
      "        print('Function not found:', tool.function.name)\n",
      "```\n",
      "\n",
      "### Generating JSON Schema from Functions\n",
      "\n",
      "The Ollama Python library uses Pydantic and docstring parsing to generate the JSON schema for functions. This allows users to easily define their own tools by providing a JSON schema.\n",
      "\n",
      "#### Example Schema Generation\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "        \"name\": \"add_two_numbers\",\n",
      "        \"description\": \"Add two numbers\",\n",
      "        \"parameters\": {\n",
      "            \"type\": \"object\",\n",
      "            \"required\": [\n",
      "                \"a\",\n",
      "                \"b\"\n",
      "            ],\n",
      "            \"properties\": {\n",
      "                \"a\": {\n",
      "                    \"type\": \"integer\",\n",
      "                    \"description\": \"The first integer number\"\n",
      "                },\n",
      "                \"b\": {\n",
      "                    \"type\": \"integer\",\n",
      "                    \"description\": \"The second integer number\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "### Additional Improvements\n",
      "\n",
      "*   Full typing support enables direct object access while maintaining existing functionality.\n",
      "*   Examples have been updated on the Ollama Python GitHub repository to showcase the new features.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "MODEL = \"llama3.2\"\n",
    "ed = Website(\"https://ollama.com/blog/functions-as-tools\")\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages_for(ed))\n",
    "print(response['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
